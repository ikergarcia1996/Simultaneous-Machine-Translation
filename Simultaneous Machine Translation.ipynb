{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "# **Simultaneous Translation**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The project\n",
    "\n",
    "\n",
    "This is a project made by Iker García for the Advanced applications on language technologies course. This course is taught in the master of natural language processing in the EHU/UPV.\n",
    "\n",
    "# The idea\n",
    "\n",
    "In the educational world there exists a big problem, the problem of different languages. For example, our university offers courses in Basque to those who do not know the language can not attend. There are also courses in Spanish that people who come from other countries (Erasmus) can not attend. And these are just some examples, the language barrier is a big problem in the educational world. That’s why my project focuses in trying to solve this problem. My idea is to implement a simultaneous translator that can automatically translate on the go a conversation from one language to another. The application will be able to listen to someone speaking and it will display as text what he has said translated to another language\n",
    "\n",
    "# How the simultaneous translation words\n",
    "\n",
    "The simultaneous translation is composed of two modules, the “speech to text” module and the “translation” module. I will focus in the second one\n",
    "\n",
    "- Speech to text: For the “speech to text” module I will use the Speech recognition API provided by Google (https://cloud.google.com/speech-to-text/) \n",
    "\n",
    "- Translator: The translator is based in the Transformer model (Vaswani et al 2017. \"Attention Is all you need\" https://arxiv.org/abs/1706.03762). I have replicated the model using the Pytorch API. \n",
    "\n",
    "- Parallel data: To train the model I have used the OpenSubtitles v2018 corpus available here: http://opus.nlpl.eu/.This corpus contains 64,7M sentences aligned for Spanish and English. \n",
    "\n",
    "\n",
    "# Resources used for the implementation\n",
    "\n",
    "- \"Attention Is all you need\": https://arxiv.org/abs/1706.03762\n",
    "- How to code The Transformer in Pytorch by Samuel Lynn-Evans: https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\n",
    "- How to use TorchText for neural machine translation, plus hack to make it 5x faster by Samuel Lynn-Evans: https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95\n",
    "- The transformer - Attention is all you need by Michał Chromiak: https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.XFW52rpKhhE\n",
    "\n",
    "- The Illustrated Transformer by Jay Alammar: http://jalammar.github.io/illustrated-transformer/\n",
    "- The Annotated Transformer by Alexander Rush: http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "\n",
    "\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "- Import the necessary modules to run the model\n",
    "- Test if a GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impor the necessary modules to run the model\n",
    "\n",
    "In the cell below, we will try to import the modules necessary to run the model if any of then cannot be loaded an exception will be displayed. If this occurs please install the missing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import copy \n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if a GPU is available\n",
    "\n",
    "If a GPU is available the output of the cell above will be the name of the GPU that Pytorch will use to run the model. If Pytorch is not able to find an available GPU make sure that Cuda and cuDNN libraries are installed or that the conda environment is correctly configured. More info here: https://pytorch.org/get-started/. The model has been tested with CUDA 10.0 and a NVIDIA RTX 2080 Ti. \n",
    "\n",
    "The model has been implemented with NVIDIA CUDA in mind. If you have an AMD GPU you may be able to adapt the code to use the ROCm platform. More info here: https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html. \n",
    "\n",
    "If there is no GPU available you may be able to use a pretrained model, however, train the model using the CPU will be very slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 970M'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or Load model\n",
    "Decide if we want to train a new model, or we want to load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained = False\n",
    "load_dataset = False\n",
    "generate_dataset=True\n",
    "\n",
    "input_lang_corpus = 'OpusCorpus/Europarl.en-es.en'\n",
    "output_lang_corpus = 'OpusCorpus/Europarl.en-es.es'\n",
    "train_file = 'OpusCorpus/train.csv'\n",
    "dev_file = \"OpusCorpus/dev.csv\"\n",
    "\n",
    "pretrained_embeddings = ''\n",
    "pretrained_model = 'weights/checkpoint_7_epoch.pth.tar'\n",
    "\n",
    "batch_size = 800 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some usefull fuctions\n",
    "\n",
    "In this section, we will implement some useful functions to print traces, memory usage... that will help us to monitor and debug our program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2019-05-05 02:27:15.523967>  Hello World\n"
     ]
    }
   ],
   "source": [
    "# Print a message and the date when the message has been printed. \n",
    "# We will print use this function to know how long each block of code has taken to run\n",
    "\n",
    "def printTrace(message):\n",
    "    print(\"<\"+ str(datetime.datetime.now()) + \">  \" +str(message))\n",
    "    \n",
    "printTrace(\"Hello World\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and load data\n",
    "\n",
    "Here we will define the functions that we will use to load and process the data.\n",
    "While processing the data (tokenize, remove some characters, filter sentences...) may be an easy task, it is very important that we try to do it as optimized and fast as possible. Otherwise, we will cause a huge bottleneck during training, the is no point in using a powerful GPU for training if the GPU spend more time waiting for the next batch than actually training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2019-05-05 02:27:15.535485>  Downloading the spacy models for tokenization...\n",
      "<2019-05-05 02:27:20.490190>  Done.\n"
     ]
    }
   ],
   "source": [
    "#Transfor every string s to the Ascii format\n",
    "def unicodeToAscii(s):\n",
    "    \n",
    "    sentence = s.split(' ')\n",
    "    \n",
    "    \n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.,!?¿])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?,¿]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(normalizeString(sentence))]\n",
    "def tokenize_es(sentence):\n",
    "    return [tok.text for tok in es.tokenizer(normalizeString(sentence))]\n",
    "\n",
    "printTrace('Downloading the spacy models for tokenization...')\n",
    "\n",
    "os.system(\"python -m spacy download en\")\n",
    "os.system(\"python -m spacy download es\")\n",
    "printTrace('Done.')\n",
    "\n",
    "en = spacy.load('en')\n",
    "es = spacy.load('es')\n",
    "\n",
    "EN_TEXT = Field(tokenize=tokenize_en)\n",
    "ES_TEXT = Field(tokenize=tokenize_es, init_token = \"<sos>\", eos_token = \"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2019-05-05 02:27:21.569800>  Loading the corpus files...\n",
      "<2019-05-05 02:27:25.128077>  Done, printing some random samples for validation: \n",
      "1 - English Sentence: \n",
      "I hope so, and I hope that this will be a strong signal that makes you sit up and listen.\n",
      "1 - Spanish Sentence: \n",
      "Eso espero, y también espero que esto sea una señal fuerte que les haga pararse a escuchar.\n",
      "2 - English Sentence: \n",
      "That is what I hope the Commission will take on board, because I believe that we will get an almost unanimous 'yes' tomorrow.\n",
      "2 - Spanish Sentence: \n",
      "Eso es lo que espero que asuma la Comisión, porque creo que mañana obtendremos un \"sí\" casi unánime.\n",
      "2 - English Sentence: \n",
      "There are, of course, some details of this resolution that I would have liked to have more of or that I would have liked to be different, but the main thing is not that all of the commas are in place; what is important is our collective will to start the process.\n",
      "2 - Spanish Sentence: \n",
      "Por supuesto, hay algunos detalles de esta resolución que me hubiera gustado desarrollar más o que me hubiera gustado que fueran diferentes, pero lo principal no es que todas las comas estén en su lugar; lo que importa es nuestra voluntad conjunta de iniciar el proceso.\n",
      "\n",
      "<2019-05-05 02:27:25.242360>  Preprocessing sentences\n",
      "<2019-05-05 02:27:25.242390>  Downloading the spacy models for tokenization...\n",
      "<2019-05-05 02:27:25.242406>  Done.\n",
      "<2019-05-05 02:27:25.242421>  Building the dataset...\n",
      "<2019-05-05 02:27:25.242435>  Transform the text files to csv format...\n",
      "<2019-05-05 02:27:26.595661>  Filtering sentences...\n",
      "<2019-05-05 02:27:33.749811>  Train/dev split...\n",
      "<2019-05-05 02:27:34.552420>  Saving csv files...\n"
     ]
    }
   ],
   "source": [
    "if generate_dataset:\n",
    "    printTrace('Loading the corpus files...')\n",
    "\n",
    "    #Read the files containing the alinged english and spanish sentences\n",
    "    original_en_corpus = open(input_lang_corpus).read().split('\\n')\n",
    "    original_es_corpus = open(output_lang_corpus).read().split('\\n')\n",
    "\n",
    "    printTrace('Done, printing some random samples for validation: ')\n",
    "\n",
    "    r = random.randint(2, (min(len(original_en_corpus)-1,len(original_es_corpus)-1)))\n",
    "\n",
    "    print('1 - English Sentence: ')\n",
    "    print(original_en_corpus[r])\n",
    "    print('1 - Spanish Sentence: ')\n",
    "    print(original_es_corpus[r])\n",
    "    print('2 - English Sentence: ')\n",
    "    print(original_en_corpus[r-1])\n",
    "    print('2 - Spanish Sentence: ')\n",
    "    print(original_es_corpus[r-1])\n",
    "    print('2 - English Sentence: ')\n",
    "    print(original_en_corpus[r-2])\n",
    "    print('2 - Spanish Sentence: ')\n",
    "    print(original_es_corpus[r-2])\n",
    "    print()\n",
    "\n",
    "\n",
    "    printTrace('Preprocessing sentences')\n",
    "\n",
    "\n",
    "    printTrace('Downloading the spacy models for tokenization...')\n",
    "    printTrace('Done.')\n",
    "    printTrace('Building the dataset...')\n",
    "\n",
    "    # Transform the dataset to csv \n",
    "\n",
    "    printTrace('Transform the text files to csv format...')\n",
    "    to_csv = {'English' : [line for line in original_en_corpus], 'Spanish': [line for line in original_es_corpus]}\n",
    "    df = pd.DataFrame(to_csv, columns=[\"English\", \"Spanish\"])\n",
    "\n",
    "    printTrace('Filtering sentences...')\n",
    "    df['en_len'] = df['English'].str.count(' ')\n",
    "    df['es_len'] = df['Spanish'].str.count(' ')\n",
    "    #Remove very long sentences\n",
    "    df = df.query('en_len < 80 & es_len < 80')\n",
    "    #Remove sentences where the lengh in the different languages is very different \n",
    "    df = df.query('es_len < en_len * 1.5 & es_len * 1.5 > en_len')\n",
    "\n",
    "\n",
    "    printTrace('Train/dev split...')\n",
    "\n",
    "    train, val = train_test_split(df, test_size=0.1)\n",
    "\n",
    "    printTrace('Saving csv files...')\n",
    "\n",
    "    train.to_csv(train_file, index=False)\n",
    "    val.to_csv(dev_file, index=False)\n",
    "    \n",
    "    del train\n",
    "    del val\n",
    "    del df\n",
    "    del original_en_corpus\n",
    "    del original_es_corpus\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2019-05-05 02:27:52.099416>  Loading data...\n",
      "<2019-05-05 02:27:52.122418>  Building vocabulary...\n",
      "Test word to index:\n",
      "0\n",
      "Test index to word:\n",
      "of\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-477babb544d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mES_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/ES_TEXT.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEN_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/EN_TEXT.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/train_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/dev_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "if generate_dataset:\n",
    "    printTrace('Loading data...')\n",
    "\n",
    "    data_fields = [('English', EN_TEXT), ('Spanish', ES_TEXT)]\n",
    "    train,dev = TabularDataset.splits(path='OpusCorpus', train='mini.csv', validation='mini.csv', format='csv', fields=data_fields)\n",
    "\n",
    "    printTrace('Building vocabulary...')\n",
    "    ES_TEXT.build_vocab(train, dev)\n",
    "    EN_TEXT.build_vocab(train, dev)\n",
    "\n",
    "\n",
    "    print('Test word to index:')\n",
    "    print(EN_TEXT.vocab.stoi['love'])\n",
    "    print('Test index to word:')\n",
    "    print(EN_TEXT.vocab.itos[8])\n",
    "    \n",
    "    pickle.dump(ES_TEXT, open('weights/ES_TEXT.pkl', 'wb'))\n",
    "    pickle.dump(EN_TEXT, open('weights/EN_TEXT.pkl', 'wb'))\n",
    "    pickle.dump(train, open('weights/train_data.pkl', 'wb'))\n",
    "    pickle.dump(dev, open('weights/dev_data.pkl', 'wb'))\n",
    "\n",
    "if load_dataset: \n",
    "\n",
    "    printTrace('Loading data...')\n",
    "    train = pickle.load(open('weights/train_data.pkl', 'rb'))\n",
    "    dev = pickle.load(open('weights/dev_data.pkl', 'rb'))\n",
    "\n",
    "    #data_fields = [('English', EN_TEXT), ('Spanish', ES_TEXT)]\n",
    "    #train,dev = TabularDataset.splits(path='OpusCorpus', train='train.csv', validation='dev.csv', format='csv', fields=data_fields)\n",
    "\n",
    "\n",
    "if load_pretrained:    \n",
    "\n",
    "    ES_TEXT = pickle.load(open('weights/ES_TEXT.pkl', 'rb'))\n",
    "    EN_TEXT = pickle.load(open('weights/EN_TEXT.pkl', 'rb'))\n",
    "\n",
    "    print('Test word to index:')\n",
    "    print(EN_TEXT.vocab.stoi['love'])\n",
    "    print('Test index to word:')\n",
    "    print(EN_TEXT.vocab.itos[8])\n",
    "    printTrace('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Fast data iterator\n",
    "This code has been extracted from: http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "It allows us to create a very fast itertator to read the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.English))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.Spanish) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    #print(max(src_elements, tgt_elements))\n",
    "    return max(src_elements, tgt_elements)\n",
    "\n",
    "\n",
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2019-05-05 02:28:41.006882>  Generating train iterator\n",
      "<2019-05-05 02:28:41.007274>  Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_iter = None\n",
    "\n",
    "\n",
    "if load_dataset or generate_dataset:\n",
    "\n",
    "    printTrace('Generating train iterator')\n",
    "\n",
    "    train_iter = MyIterator(train, batch_size=batch_size, device=device,\n",
    "                            repeat=False, sort_key= lambda x:\n",
    "                            (len(x.English), len(x.Spanish)),\n",
    "                            batch_size_fn=batch_size_fn, train=True,\n",
    "                            shuffle=True)\n",
    "    \n",
    "\n",
    "    printTrace('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_input(batch):\n",
    "    input_seq = batch.English.transpose(0,1)\n",
    "    input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "    input_msk = (input_seq != input_pad).unsqueeze(1)\n",
    "    \n",
    "    return input_seq, input_msk\n",
    "\n",
    "def create_mask_output(batch):\n",
    "    output_seq = batch.Spanish.transpose(0,1)\n",
    "    output_pad = ES_TEXT.vocab.stoi['<pad>']\n",
    "    output_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "    size = target_seq.size(1)\n",
    "    #Make sure that the decoder only sees the encoder ouput until the last word predicted. \n",
    "    nopeak_mask = np.triu(np.ones(1, size, size),k=1).astype('uint8')\n",
    "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "    output_msk = target_msk & nopeak_mask\n",
    "    \n",
    "    return output_seq, output_msk\n",
    "\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    \n",
    "    src_mask = (src != EN_TEXT.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != ES_TEXT.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = nopeak_mask(size)\n",
    "        if trg.is_cuda:\n",
    "            np_mask.cuda()\n",
    "        trg_mask = trg_mask & np_mask\n",
    "        \n",
    "    else:\n",
    "        trg_mask = None\n",
    "    return src_mask, trg_mask\n",
    "\n",
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)),k=1).astype('uint8')\n",
    "    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
    "    np_mask = np_mask.cuda()\n",
    "    return np_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The transformer\n",
    "\n",
    "In this section of the notebook we will define the trasnformer model. \n",
    "![TransformerCompleteModel](Images/TheTransformerModel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Word Embeddings\n",
    "\n",
    "Since we have millions of sentences to use for trainning we will train our own word embeddings with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self,x):\n",
    "        print(x)\n",
    "        return self.emb(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The positional encoding\n",
    "\n",
    "Since this model does not use recurrent neural networks, we need to give to the model the information of the order of the words in the input and output sentence, otherwise the model will not be able to know that \"John gives the pencil to Mery\" has a different meaning than \"Mary gives the pencil to John\". \n",
    "To achieve this we will use positional encoding vectors. We will create positional vectors using the formula proposed by Vaswani et al. and we will add this vectors to the regular word embeddings. This way our word embeddings will represent the meaning of the word and the position in the sentence of the words.\n",
    "\n",
    "![PosEncodingFormula1](Images/PosEncodingFormula1.png)\n",
    "![PosEncodingFormula1](Images/PosEncodingFormula2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_sentence_len=80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_sentence_len, d_model)\n",
    "        for pos in range(max_sentence_len):\n",
    "            for i in range(0,d_model,2):\n",
    "                pe[pos,i] = math.sin(pos/10000.0 ** (2*i/d_model))\n",
    "                pe[pos,i+1] = math.cos(pos/10000.0 ** ((2 * (i + 1)/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Escale embeddings to avoid positional vectors to dominate word embeddings and cause loose of information\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len],requires_grad=False).cuda()\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Multi-Header attention\n",
    "\n",
    "<img src=\"Images/MHA.png\" width=\"350\">\n",
    "\n",
    "\n",
    "\n",
    "STEP 1:\n",
    "\n",
    "<img src=\"Images/mattention1.png\" width=\"350\">\n",
    "\n",
    "\n",
    "STEP 2: \n",
    "<img src=\"Images/mattention2.png\" width=\"450\">\n",
    "\n",
    "Images from: http://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "        \n",
    "        #STEP 1\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        #STEP 2\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            #print('scores: ' + str(scores.size()))\n",
    "            #print('mask: ' + str(mask.size()))\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        scores = self.dropout(scores)\n",
    "        scores = torch.matmul(scores, v)\n",
    "        \n",
    "        \n",
    "        \n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Feed-Forward Network\n",
    "Simple perceptron with Relu activation\n",
    "\n",
    "<img src=\"Images/perceptron.gif\" width=\"250\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        r = F.relu(self.w_1(x))\n",
    "        r = self.dropout(r)\n",
    "        r = self.w_2(r)\n",
    "        return r\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Normalization\n",
    "\n",
    "We will normalioze the returns between each layer in the encoder/decoder\n",
    "\n",
    "<img src=\"Images/Normalization.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Encoder Layer\n",
    "<img src=\"Images/encoder.png\" width=\"650\">\n",
    "Image from: http://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.att = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        self_att = self.att(x2,x2,x2,mask)\n",
    "        self_att = self.dropout_1(self_att)\n",
    "        x = x + self_att\n",
    "        \n",
    "        x2  = self.norm_2(x)\n",
    "        feed_forward = self.ff(x2)\n",
    "        feed_forward = self.dropout_2(feed_forward)\n",
    "        x = x + feed_forward\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Decoder Layer\n",
    "<img src=\"Images/decoder.png\" width=\"750\">\n",
    "Image from: http://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model).cuda()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "\n",
    "        x2 = self.norm_1(x)\n",
    "        self_att = self.attn_1(x2, x2, x2, trg_mask)\n",
    "        self_att = self.dropout_1(self_att)\n",
    "\n",
    "        x = x + self_att\n",
    "\n",
    "        x2 = self.norm_2(x)\n",
    "        encoder_decoder_att =  self.attn_2(x2, e_outputs, e_outputs, src_mask)\n",
    "        encoder_decoder_att = self.dropout_2(encoder_decoder_att)\n",
    "\n",
    "        x = x + encoder_decoder_att\n",
    "\n",
    "\n",
    "        x2 = self.norm_3(x)\n",
    "        feed_forward = self.ff(x2)\n",
    "        feed_forward = self.dropout_3(feed_forward)\n",
    "\n",
    "        x = x + feed_forward\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Transformer: Encoder and Decoder\n",
    "<img src=\"Images/EncoderDecoder.png\" width=\"750\">\n",
    "Image from: http://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        \n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()   \n",
    "        self.N=N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        \n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()   \n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# Training\n",
    "\n",
    "Inicialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "src_vocab = len(EN_TEXT.vocab)\n",
    "trg_vocab = len(ES_TEXT.vocab)\n",
    "\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads).cuda()\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "        \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9) \n",
    "\n",
    "\n",
    "\n",
    "if load_pretrained:\n",
    "    checkpoint = torch.load(pretrained_model)\n",
    "    model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate a sentence (for dev acc): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def evaluate(model, num_eval = 5000):\n",
    "    devf = pd.read_csv('OpusCorpus/train.csv',nrows=num_eval)\n",
    "    model.eval()\n",
    "    english_sentences= devf['English'].values\n",
    "    spanish_sentences= devf['Spanish'].values\n",
    "    max_len = 80\n",
    "    cc = 0\n",
    "    ccn = 0\n",
    "    \n",
    "    for x in tqdm(range(len(english_sentences))):\n",
    "        src= english_sentences[x]\n",
    "        trg = spanish_sentences[x]\n",
    "        src = tokenize_en(src)\n",
    "        src= Variable(torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in src]])).cuda()\n",
    "        \n",
    "\n",
    "        src_mask = (src != EN_TEXT.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "        e_outputs = model.encoder(src, src_mask)\n",
    "    \n",
    "        outputs = torch.zeros(max_len).type_as(src.data)\n",
    "        outputs[0] = torch.LongTensor([ES_TEXT.vocab.stoi['<sos>']])\n",
    "        \n",
    "        for i in range(1, max_len):    \n",
    "            \n",
    "\n",
    "            trg_mask = np.triu(np.ones((1, i, i)),k=1).astype('uint8')\n",
    "            trg_mask= Variable(torch.from_numpy(trg_mask) == 0).cuda()\n",
    "           \n",
    "            out = model.out(model.decoder(outputs[:i].unsqueeze(0),\n",
    "            e_outputs, src_mask, trg_mask))\n",
    "            out = F.softmax(out, dim=-1)\n",
    "            val, ix = out[:, -1].data.topk(1)\n",
    "\n",
    "            outputs[i] = ix[0][0]\n",
    "            if ix[0][0] == ES_TEXT.vocab.stoi['<eos>']:\n",
    "                break\n",
    "                               \n",
    "        r_sentence = ' '.join([ES_TEXT.vocab.itos[ix] for ix in outputs[:i]])\n",
    "                                   \n",
    "        cc+=similar(r_sentence,trg)\n",
    "        ccn+=1\n",
    "        \n",
    "    return cc/ccn\n",
    "                                   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, print_every=100, save_every=10000, save_path = 'weights/Model.pytorch'):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0,1)\n",
    "            trg = batch.Spanish.transpose(0,1)\n",
    "            print(src.shape)\n",
    "            print(trg.shape)\n",
    "            print(type(src))\n",
    "            #print(src)\n",
    "            #print(trg)\n",
    "            #print('src: ' + str(src.size()))\n",
    "            #print('trg: ' + str(trg.size()))\n",
    "            \n",
    "            #@todo: FIX this in data loading\n",
    "            if trg.size()[1] > 80 or src.size()[1]>80:\n",
    "                continue\n",
    "            trg_input = trg[:, :-1]\n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            ys = trg[:, 1:].contiguous().view(-1)\n",
    "            #print('mask training: ' + str(trg_mask.size()))\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),ys, ignore_index=ES_TEXT.vocab.stoi['<pad>'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                #dev_score = evaluate(model)\n",
    "                printTrace(\"epoch %d, iter = %d, loss = %.3f\" % (epoch + 1, i + 1, loss_avg))\n",
    "                total_loss = 0\n",
    "            # Save checkpoint\n",
    "            if (i+1) % save_every == 0:\n",
    "                torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([10, 33])\n",
      "torch.Size([10, 37])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[ 55,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  75, 118,  34,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [111, 116,   4, 107, 109,   4,  58,  57,  28,  56,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  80,  67,  65,   2,  69,  49,  19,   2,  61,  76,  12,  97,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 14, 115,   9, 117,  31,  25,   2,  20,  74,  62,   2,  48,  42,  51,\n",
      "          88,  82,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 64,  41,  24, 112,   4,  70,   9,  38,  33,   4,  10,  12, 101,   7,\n",
      "          18,   4,  30,  20,  10,  26,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 98,   3,  25,  95,   4,  15,  16,   3,   2,  91,  89,  72,   2,  59,\n",
      "          29,  15,  16,  83,   8,  68,  92,   5,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 24,  52,  18,  39, 108,   2,  94,   8,  60,  27, 114,  99,  17, 102,\n",
      "          73, 104,   7,  17,  96,  35,  13,  37,  93, 106,   5,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [  2,  45,  11,  23,   3,  84,   2,  46,  11,  23,   3, 110,  13,  81,\n",
      "          86,  47,  22, 103,  21,   3,  79,  53,  66,  63,  22,  54,  21,   5,\n",
      "           1,   1,   1,   1,   1],\n",
      "        [ 77,  90,   3,  14, 100,  71,   4, 105,  32,  85,   6,   4,   9,   6,\n",
      "           3,  50, 113,  87,   8,   2,   6,   3,  78,   2, 119,  40,   2,  44,\n",
      "          36,   7,  19,  43,   5]], device='cuda:0')\n",
      "tensor([[  2, 106,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  15,  32,  94,  35,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  95,  70,  13,  61,   4,  68,   7,  59,   8,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   4,  45,  14,  15,  80,  20,  53,   5,   9,  92,  10,  51,  46,\n",
      "           4,  16, 104,  93,   4,  97,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  67, 114,  36,  14,  81,  54,  10,  83,  60,  20,  86,  52,  38,\n",
      "          78,  37,   8,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 116,  11,   9, 111,   4,  69,  17,   9,  34,  13,  19,   4, 100,\n",
      "          18,  12,  10,  99,   4,  24,  19,  30,   3,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,   7, 101,  72,   5,  14,  98,  13,   6,  23,  22,   5,   6,  89,\n",
      "          33,   9,  66,  62,  11,  29,   4, 108,  91,   6,  71,  47,   6,  23,\n",
      "          22,   8,   3,   1,   1,   1,   1,   1],\n",
      "        [  2,  49,  17,   6,  50,   4,   6,  63,   4, 112, 103, 113,   7,  24,\n",
      "          58,  76,  87,  18,   7,  16, 115,  96,  12,   9,  65,  31,  48,   8,\n",
      "           3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  27, 109,   5,   6,  41,  11,  28,   5,  77,   6,  43,  11,  28,\n",
      "           5,  12, 110,  42,  85,   7,  25,   4,  26, 105,   5,  10,  75,  12,\n",
      "          73,  17,   7,  25,   4,  26,  56,   8],\n",
      "        [  2, 102,  90,   5,  74,  64,  88,  29,  21,  79,   5, 107,  55,  84,\n",
      "           4,   6,  21,   5,  44,  16,  82,  27,  15,  57,  40,  18,   7,  39,\n",
      "           8,   3,   1,   1,   1,   1,   1,   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if load_pretrained == False:\n",
    "    train_model(model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, sentence):\n",
    "        model.eval()\n",
    "        max_len = 80\n",
    "        src = tokenize_en(sentence)\n",
    "        src= Variable(torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in src]])).cuda()\n",
    "        \n",
    "\n",
    "        src_mask = (src != EN_TEXT.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "        e_outputs = model.encoder(src, src_mask)\n",
    "        \n",
    "        outputs = torch.zeros(max_len).type_as(src.data)\n",
    "        outputs[0] = torch.LongTensor([ES_TEXT.vocab.stoi['<sos>']])\n",
    "        \n",
    "        for i in range(1, max_len):    \n",
    "            \n",
    "\n",
    "            trg_mask = np.triu(np.ones((1, i, i)),k=1).astype('uint8')\n",
    "            trg_mask= Variable(torch.from_numpy(trg_mask) == 0).cuda()\n",
    "           \n",
    "            out = model.out(model.decoder(outputs[:i].unsqueeze(0),\n",
    "            e_outputs, src_mask, trg_mask))\n",
    "            out = F.softmax(out, dim=-1)\n",
    "            val, ix = out[:, -1].data.topk(1)\n",
    "\n",
    "            outputs[i] = ix[0][0]\n",
    "            if ix[0][0] == ES_TEXT.vocab.stoi['<eos>']:\n",
    "                break\n",
    "                               \n",
    "        return ' '.join([ES_TEXT.vocab.itos[ix] for ix in outputs[1:i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estoy haciendo una presentacion sobre el procesamiento de idiomas'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model,'I am doing a presentation about natual language processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pruebas de pruebas de pruebas de pruebas'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import the PyAudio C module '_portaudio'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libportaudio.so.2: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1cab1c630527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogletrans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# attempt to import PortAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0m_portaudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not import the PyAudio C module '_portaudio'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libportaudio.so.2: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "#FROM GOOGLE API\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "from googletrans import Translator\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "import os \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/iker/Documents/SpeachToText-78c991f80cbb.json\"\n",
    "\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)\n",
    "\n",
    "\n",
    "def listen_print_loop(responses, simultaneous_translator,custom_translator, model=None):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not custom_translator:\n",
    "        translator = Translator()\n",
    "        \n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "        #print(transcript)\n",
    "        \n",
    "        #print(result.is_final)\n",
    "        if not result.is_final:\n",
    "            \n",
    "            if simultaneous_translator:\n",
    "\n",
    "                if custom_translator:\n",
    "                    t= translate(model,transcript)\n",
    "                else:\n",
    "                    t = translator.translate(transcript, src='en', dest='es').text\n",
    "                \n",
    "                \n",
    "                \n",
    "                sys.stdout.write(t + overwrite_chars + '\\r')\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                num_chars_printed = len(t)\n",
    "\n",
    "            #else:\n",
    "            #    sys.stdout.write( t + '\\r')\n",
    "            #    sys.stdout.flush()\n",
    "\n",
    "                \n",
    "            #num_chars_printed = len(str(t))\n",
    "        else:\n",
    "            print('Speech to Tex: ' + transcript + overwrite_chars)\n",
    "         \n",
    "            \n",
    "\n",
    "            if custom_translator:\n",
    "                print('Translator: ' + translate(model,transcript))\n",
    "            else:\n",
    "                print('Translator: ' + translator.translate(transcript, src='en', dest='es').text)\n",
    "\n",
    "            \n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                print('Exiting..')\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0\n",
    "\n",
    "\n",
    "def main(model, simultaneous_translator=True,custom_translator=True):\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = 'en-UK'  # a BCP-47 language tag\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code)\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "        # Now, put the transcription responses to use.\n",
    "        listen_print_loop(responses, simultaneous_translator,custom_translator, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2c00813f156c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimultaneous_translator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_translator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-1cab1c630527>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, simultaneous_translator, custom_translator)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_recognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Now, put the transcription responses to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mlisten_print_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimultaneous_translator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_translator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-1cab1c630527>\u001b[0m in \u001b[0;36mlisten_print_loop\u001b[0;34m(responses, simultaneous_translator, custom_translator, model)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mnum_chars_printed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(model, simultaneous_translator=True,custom_translator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "- This is a test of simultaneous translation\n",
    "- Please, say your name\n",
    "- Hi class, please open the book in chapter one\n",
    "- Now everybody can attend a class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
